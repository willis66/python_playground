{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.00</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>28.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                      Name  \\\n",
       "886          887         0       2                     Montvila, Rev. Juozas   \n",
       "887          888         1       1              Graham, Miss. Margaret Edith   \n",
       "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889          890         1       1                     Behr, Mr. Karl Howell   \n",
       "890          891         0       3                       Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
       "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
       "887  female  19.0      0      0      112053  30.00   B42        S  \n",
       "888  female  28.7      1      2  W./C. 6607  23.45   NaN        S  \n",
       "889    male  26.0      0      0      111369  30.00  C148        C  \n",
       "890    male  32.0      0      0      370376   7.75   NaN        Q  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "test_data = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# train_data.head()\n",
    "train_data.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.drop(labels=[\"Cabin\", \"Name\", \"Ticket\", \"PassengerId\"], axis=1)\n",
    "# train_data = train_data.dropna() # i just changed both by hand to include average age when there was no other data availible\n",
    "\n",
    "test_data = test_data.drop(labels=[\"Cabin\", \"Name\", \"Ticket\"], axis=1)\n",
    "test_ids = test_data.pop(\"PassengerId\")\n",
    "# test_data = test_data.dropna()\n",
    "\n",
    "train_data = train_data.replace(\"male\", 1).replace(\"female\", 0).replace(\"S\", 0).replace(\"C\", 1).replace(\"Q\", 2)\n",
    "test_data = test_data.replace(\"male\", 1).replace(\"female\", 0).replace(\"S\", 0).replace(\"C\", 1).replace(\"Q\", 2)\n",
    "train_data.tail()\n",
    "\n",
    "print(train_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex   Age  SibSp  Parch   Fare  Embarked\n",
       "886       2    1  27.0      0      0  13.00       0.0\n",
       "887       1    0  19.0      0      0  30.00       0.0\n",
       "888       3    0  28.7      1      2  23.45       0.0\n",
       "889       1    1  26.0      0      0  30.00       1.0\n",
       "890       3    1  32.0      0      0   7.75       2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data.copy()\n",
    "# have to split data lol\n",
    "y_train = x_train.pop(\"Survived\")\n",
    "x_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.836071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.477990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>29.765062</td>\n",
       "      <td>13.008481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.523008</td>\n",
       "      <td>1.102743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.381594</td>\n",
       "      <td>0.806057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>32.204208</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.362205</td>\n",
       "      <td>0.636157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean        std\n",
       "Pclass     2.308642   0.836071\n",
       "Sex        0.647587   0.477990\n",
       "Age       29.765062  13.008481\n",
       "SibSp      0.523008   1.102743\n",
       "Parch      0.381594   0.806057\n",
       "Fare      32.204208  49.693429\n",
       "Embarked   0.362205   0.636157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.describe().transpose()[[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 21:53:48.500788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.308642  ,  0.64758706, 29.76506   ,  0.5230078 ,  0.38159373,\n",
       "        32.20421   ,         nan]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.asarray(x_train).astype('float32')\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(x_train))\n",
    "normalizer.mean.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    global learning_rate\n",
    "    learning_rate = hp.Choice('learning_rate', values=[5e-1, 1e-1, 1e-2, 1e-3, 1e-4])\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    hp_units2 = hp.Int(\"units2\", min_value=32, max_value=512, step=32)\n",
    "    hp_units3 = hp.Int(\"units3\", min_value=32, max_value=512, step=32)\n",
    "    hp_dropout = hp.Float(\"dropout\", min_value=0, max_value=0.5)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        normalizer, \n",
    "        keras.layers.Dense(hp_units, kernel_regularizer=keras.regularizers.l2(0.001), activation=\"relu\"),\n",
    "        keras.layers.Dropout(hp_dropout),\n",
    "        keras.layers.Dense(hp_units2, kernel_regularizer=keras.regularizers.l2(0.001), activation=\"relu\"),\n",
    "        keras.layers.Dropout(hp_dropout),\n",
    "        keras.layers.Dense(hp_units3, kernel_regularizer=keras.regularizers.l2(0.001), activation=\"relu\"),\n",
    "        keras.layers.Dropout(hp_dropout),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "    return model\n",
    "# model_builder(normalizer).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probably should add early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 200 Complete [00h 00m 03s]\n",
      "val_binary_accuracy: 0.6424580812454224\n",
      "\n",
      "Best val_binary_accuracy So Far: 0.6424580812454224\n",
      "Total elapsed time: 00h 08m 21s\n",
      "\n",
      "Search: Running Trial #201\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.1               |0.0001            |learning_rate\n",
      "256               |64                |units\n",
      "160               |160               |units2\n",
      "480               |384               |units3\n",
      "0.34345           |0.44654           |dropout\n",
      "12                |2                 |tuner/epochs\n",
      "4                 |0                 |tuner/initial_epoch\n",
      "3                 |4                 |tuner/bracket\n",
      "1                 |0                 |tuner/round\n",
      "0159              |None              |tuner/trial_id\n",
      "\n",
      "Epoch 5/12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/williserdman/Documents/code/python_playground/kaggle/titanic/main.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williserdman/Documents/code/python_playground/kaggle/titanic/main.ipynb#ch0000007?line=0'>1</a>\u001b[0m tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mHyperband(model_builder, objective\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_binary_accuracy\u001b[39m\u001b[39m\"\u001b[39m, max_epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, directory\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmy_dir\u001b[39m\u001b[39m\"\u001b[39m, project_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkaggle_titanic\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/williserdman/Documents/code/python_playground/kaggle/titanic/main.ipynb#ch0000007?line=1'>2</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 179\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    180\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras_tuner/tuners/hyperband.py:384\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/epochs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    383\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/initial_epoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Hyperband, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:294\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    293\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 294\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    296\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    297\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    221\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 222\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    223\u001b[0m \u001b[39mreturn\u001b[39;00m tuner_utils\u001b[39m.\u001b[39mconvert_to_metrics_dict(\n\u001b[1;32m    224\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 963\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    964\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    966\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 785\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn\u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    786\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    789\u001b[0m   \u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2480\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2478\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2479\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 2480\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m   2481\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m   cache_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mgeneralize(cache_key)\n\u001b[1;32m   2709\u001b[0m   (args, kwargs) \u001b[39m=\u001b[39m cache_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 2711\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[1;32m   2712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                          graph_function)\n\u001b[1;32m   2715\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2622\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m   2623\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   2624\u001b[0m ]\n\u001b[1;32m   2625\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m   2626\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 2627\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m   2628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2629\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m   2630\u001b[0m         args,\n\u001b[1;32m   2631\u001b[0m         kwargs,\n\u001b[1;32m   2632\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   2633\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m   2634\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m   2635\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m   2636\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m   2637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m   2638\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m   2639\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   2640\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   2641\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   2642\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   2643\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2644\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1139\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1141\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1143\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1116\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1117\u001b[0m       original_func,\n\u001b[1;32m   1118\u001b[0m       args,\n\u001b[1;32m   1119\u001b[0m       kwargs,\n\u001b[1;32m   1120\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1121\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1122\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1123\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1124\u001b[0m       ))\n\u001b[1;32m   1125\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/43/vg26n99561513nys7wd_r9pc0000gn/T/__autograph_generated_fileqds4d3ii.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/engine/training.py:1040\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[1;32m   1038\u001b[0m       run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1039\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1040\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m   1041\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1042\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1043\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1308\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1311\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1312\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   2887\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2888\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3688\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 3689\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/engine/training.py:1030\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1030\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m   1031\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/engine/training.py:894\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mminimize(loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables, tape\u001b[39m=\u001b[39mtape)\n\u001b[0;32m--> 894\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/engine/training.py:987\u001b[0m, in \u001b[0;36mModel.compute_metrics\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[39m\"\"\"Update metric states and collect all metrics to be returned.\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \n\u001b[1;32m    954\u001b[0m \u001b[39mSubclasses can optionally override this method to provide custom metric\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39m  `{'loss': 0.2, 'accuracy': 0.7}`.\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[39mdel\u001b[39;00m x  \u001b[39m# The default implementation does not use `x`.\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompiled_metrics\u001b[39m.\u001b[39;49mupdate_state(y, y_pred, sample_weight)\n\u001b[1;32m    988\u001b[0m \u001b[39m# Collect metrics to return\u001b[39;00m\n\u001b[1;32m    989\u001b[0m return_metrics \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/engine/compile_utils.py:501\u001b[0m, in \u001b[0;36mMetricsContainer.update_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    499\u001b[0m   \u001b[39mif\u001b[39;00m metric_obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m   metric_obj\u001b[39m.\u001b[39;49mupdate_state(y_t, y_p, sample_weight\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m    503\u001b[0m \u001b[39mfor\u001b[39;00m weighted_metric_obj \u001b[39min\u001b[39;00m weighted_metric_objs:\n\u001b[1;32m    504\u001b[0m   \u001b[39mif\u001b[39;00m weighted_metric_obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/utils/metrics_utils.py:70\u001b[0m, in \u001b[0;36mupdate_state_wrapper.<locals>.decorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mTrying to run metric.update_state in replica context when \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     66\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mthe metric was not created in TPUStrategy scope. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     67\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mMake sure the keras Metric is created in TPUstrategy scope. \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[39mwith\u001b[39;00m tf_utils\u001b[39m.\u001b[39mgraph_context_for_symbolic_tensors(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 70\u001b[0m   update_op \u001b[39m=\u001b[39m update_state_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m update_op \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# update_op will be None in eager execution.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m   metric_obj\u001b[39m.\u001b[39madd_update(update_op)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/metrics/base_metric.py:140\u001b[0m, in \u001b[0;36mMetric.__new__.<locals>.update_state_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m control_status \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[1;32m    138\u001b[0m ag_update_state \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m    139\u001b[0m     obj_update_state, control_status)\n\u001b[0;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m ag_update_state(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/metrics/base_metric.py:646\u001b[0m, in \u001b[0;36mMeanMetricWrapper.update_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    642\u001b[0m y_pred, y_true \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[1;32m    643\u001b[0m     y_pred, y_true)\n\u001b[1;32m    645\u001b[0m ag_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fn, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx())\n\u001b[0;32m--> 646\u001b[0m matches \u001b[39m=\u001b[39m ag_fn(y_true, y_pred, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fn_kwargs)\n\u001b[1;32m    647\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(MeanMetricWrapper, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mupdate_state(\n\u001b[1;32m    648\u001b[0m     matches, sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/keras/utils/metrics_utils.py:859\u001b[0m, in \u001b[0;36mbinary_matches\u001b[0;34m(y_true, y_pred, threshold)\u001b[0m\n\u001b[1;32m    857\u001b[0m threshold \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(threshold, y_pred\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    858\u001b[0m y_pred \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(y_pred \u001b[39m>\u001b[39m threshold, y_pred\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m--> 859\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcast(tf\u001b[39m.\u001b[39;49mequal(y_true, y_pred), backend\u001b[39m.\u001b[39;49mfloatx())\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1002\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m   1000\u001b[0m   x \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(x, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1001\u001b[0m   \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m base_type:\n\u001b[0;32m-> 1002\u001b[0m     x \u001b[39m=\u001b[39m gen_math_ops\u001b[39m.\u001b[39;49mcast(x, base_type, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1003\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mis_complex \u001b[39mand\u001b[39;00m base_type\u001b[39m.\u001b[39mis_floating:\n\u001b[1;32m   1004\u001b[0m   logging\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mCasting complex to real discards imaginary part.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:2014\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   2012\u001b[0m   Truncate \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2013\u001b[0m Truncate \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_bool(Truncate, \u001b[39m\"\u001b[39m\u001b[39mTruncate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2014\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m   2015\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mCast\u001b[39;49m\u001b[39m\"\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, DstT\u001b[39m=\u001b[39;49mDstT, Truncate\u001b[39m=\u001b[39;49mTruncate, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   2016\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m   2017\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[1;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:694\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    692\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    693\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    695\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    696\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3754\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3751\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3752\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3753\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3754\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[1;32m   3755\u001b[0m       node_def,\n\u001b[1;32m   3756\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3757\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m   3758\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m   3759\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[1;32m   3760\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m   3761\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[1;32m   3762\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   3763\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   3764\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2131\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2128\u001b[0m     op_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_get_op_def(node_def\u001b[39m.\u001b[39mop)\n\u001b[1;32m   2129\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op \u001b[39m=\u001b[39m _create_c_op(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph, node_def, inputs,\n\u001b[1;32m   2130\u001b[0m                             control_input_ops, op_def)\n\u001b[0;32m-> 2131\u001b[0m   name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   2133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traceback \u001b[39m=\u001b[39m tf_stack\u001b[39m.\u001b[39mextract_stack_for_node(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op)\n\u001b[1;32m   2135\u001b[0m \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/util/compat.py:116\u001b[0m, in \u001b[0;36mas_str\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mas_str\u001b[39m(bytes_or_text, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 116\u001b[0m   \u001b[39mreturn\u001b[39;00m as_text(bytes_or_text, encoding)\n",
      "File \u001b[0;32m~/Documents/code/python_playground/kaggle/env/lib/python3.8/site-packages/tensorflow/python/util/compat.py:106\u001b[0m, in \u001b[0;36mas_text\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39m\"\"\"Converts any string-like python input types to unicode.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m \u001b[39mReturns the input as a unicode string. Uses utf-8 encoding for text\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m  TypeError: If `bytes_or_text` is not a binary or unicode string.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m# Validate encoding, a LookupError will be raised if invalid.\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m encoding \u001b[39m=\u001b[39m codecs\u001b[39m.\u001b[39;49mlookup(encoding)\u001b[39m.\u001b[39mname\n\u001b[1;32m    107\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(bytes_or_text, _six\u001b[39m.\u001b[39mtext_type):\n\u001b[1;32m    108\u001b[0m   \u001b[39mreturn\u001b[39;00m bytes_or_text\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder, objective=\"val_binary_accuracy\", max_epochs=100, factor=3, directory=\"my_dir\", project_name=\"kaggle_titanic\")\n",
    "tuner.search(x_train, y_train, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameter search is complete.\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"The hyperparameter search is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_binary_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/williserdman/Documents/code/python_playground/kaggle/titanic/main.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williserdman/Documents/code/python_playground/kaggle/titanic/main.ipynb#ch0000010?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mbuild(best_hps)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williserdman/Documents/code/python_playground/kaggle/titanic/main.ipynb#ch0000010?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(x_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, validation_split\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/williserdman/Documents/code/python_playground/kaggle/titanic/main.ipynb#ch0000010?line=2'>3</a>\u001b[0m val_acc_per_epoch \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mval_binary_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williserdman/Documents/code/python_playground/kaggle/titanic/main.ipynb#ch0000010?line=3'>4</a>\u001b[0m best_epoch \u001b[39m=\u001b[39m val_acc_per_epoch\u001b[39m.\u001b[39mindex(\u001b[39mmax\u001b[39m(val_acc_per_epoch)) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/williserdman/Documents/code/python_playground/kaggle/titanic/main.ipynb#ch0000010?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest epoch: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (best_epoch,))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_binary_accuracy'"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.2, verbose=0)\n",
    "val_acc_per_epoch = history.history['val_binary_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/436\n",
      "23/23 [==============================] - 1s 5ms/step - loss: 1.1561 - binary_accuracy: 0.7598\n",
      "Epoch 2/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.9208 - binary_accuracy: 0.7992\n",
      "Epoch 3/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.7885 - binary_accuracy: 0.8272\n",
      "Epoch 4/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.7131 - binary_accuracy: 0.8188\n",
      "Epoch 5/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.6529 - binary_accuracy: 0.8244\n",
      "Epoch 6/436\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.6065 - binary_accuracy: 0.8315\n",
      "Epoch 7/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5869 - binary_accuracy: 0.8357\n",
      "Epoch 8/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5490 - binary_accuracy: 0.8343\n",
      "Epoch 9/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5381 - binary_accuracy: 0.8287\n",
      "Epoch 10/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5195 - binary_accuracy: 0.8385\n",
      "Epoch 11/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4978 - binary_accuracy: 0.8483\n",
      "Epoch 12/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4875 - binary_accuracy: 0.8483\n",
      "Epoch 13/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4798 - binary_accuracy: 0.8399\n",
      "Epoch 14/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4730 - binary_accuracy: 0.8455\n",
      "Epoch 15/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4682 - binary_accuracy: 0.8441\n",
      "Epoch 16/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4669 - binary_accuracy: 0.8413\n",
      "Epoch 17/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4469 - binary_accuracy: 0.8427\n",
      "Epoch 18/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4529 - binary_accuracy: 0.8413\n",
      "Epoch 19/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4373 - binary_accuracy: 0.8469\n",
      "Epoch 20/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4371 - binary_accuracy: 0.8385\n",
      "Epoch 21/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4462 - binary_accuracy: 0.8483\n",
      "Epoch 22/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4301 - binary_accuracy: 0.8427\n",
      "Epoch 23/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4317 - binary_accuracy: 0.8469\n",
      "Epoch 24/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4207 - binary_accuracy: 0.8441\n",
      "Epoch 25/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4103 - binary_accuracy: 0.8525\n",
      "Epoch 26/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4122 - binary_accuracy: 0.8483\n",
      "Epoch 27/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4131 - binary_accuracy: 0.8497\n",
      "Epoch 28/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4104 - binary_accuracy: 0.8413\n",
      "Epoch 29/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4041 - binary_accuracy: 0.8610\n",
      "Epoch 30/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4063 - binary_accuracy: 0.8567\n",
      "Epoch 31/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4121 - binary_accuracy: 0.8469\n",
      "Epoch 32/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.4101 - binary_accuracy: 0.8427\n",
      "Epoch 33/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4014 - binary_accuracy: 0.8553\n",
      "Epoch 34/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3991 - binary_accuracy: 0.8539\n",
      "Epoch 35/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3920 - binary_accuracy: 0.8581\n",
      "Epoch 36/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3993 - binary_accuracy: 0.8567\n",
      "Epoch 37/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4053 - binary_accuracy: 0.8441\n",
      "Epoch 38/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3904 - binary_accuracy: 0.8610\n",
      "Epoch 39/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3840 - binary_accuracy: 0.8624\n",
      "Epoch 40/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3887 - binary_accuracy: 0.8567\n",
      "Epoch 41/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3892 - binary_accuracy: 0.8666\n",
      "Epoch 42/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3906 - binary_accuracy: 0.8511\n",
      "Epoch 43/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3914 - binary_accuracy: 0.8596\n",
      "Epoch 44/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3857 - binary_accuracy: 0.8511\n",
      "Epoch 45/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3812 - binary_accuracy: 0.8596\n",
      "Epoch 46/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3827 - binary_accuracy: 0.8553\n",
      "Epoch 47/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3811 - binary_accuracy: 0.8539\n",
      "Epoch 48/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3865 - binary_accuracy: 0.8539\n",
      "Epoch 49/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3803 - binary_accuracy: 0.8652\n",
      "Epoch 50/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3777 - binary_accuracy: 0.8624\n",
      "Epoch 51/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3763 - binary_accuracy: 0.8666\n",
      "Epoch 52/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3880 - binary_accuracy: 0.8525\n",
      "Epoch 53/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3745 - binary_accuracy: 0.8722\n",
      "Epoch 54/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3739 - binary_accuracy: 0.8610\n",
      "Epoch 55/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3788 - binary_accuracy: 0.8610\n",
      "Epoch 56/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3701 - binary_accuracy: 0.8610\n",
      "Epoch 57/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3758 - binary_accuracy: 0.8638\n",
      "Epoch 58/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3767 - binary_accuracy: 0.8610\n",
      "Epoch 59/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3723 - binary_accuracy: 0.8567\n",
      "Epoch 60/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3747 - binary_accuracy: 0.8652\n",
      "Epoch 61/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3721 - binary_accuracy: 0.8708\n",
      "Epoch 62/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3771 - binary_accuracy: 0.8638\n",
      "Epoch 63/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3595 - binary_accuracy: 0.8680\n",
      "Epoch 64/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3623 - binary_accuracy: 0.8652\n",
      "Epoch 65/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3725 - binary_accuracy: 0.8652\n",
      "Epoch 66/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3702 - binary_accuracy: 0.8708\n",
      "Epoch 67/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3667 - binary_accuracy: 0.8680\n",
      "Epoch 68/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3667 - binary_accuracy: 0.8694\n",
      "Epoch 69/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3723 - binary_accuracy: 0.8638\n",
      "Epoch 70/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3688 - binary_accuracy: 0.8581\n",
      "Epoch 71/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3676 - binary_accuracy: 0.8553\n",
      "Epoch 72/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3608 - binary_accuracy: 0.8624\n",
      "Epoch 73/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3705 - binary_accuracy: 0.8666\n",
      "Epoch 74/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3773 - binary_accuracy: 0.8624\n",
      "Epoch 75/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3609 - binary_accuracy: 0.8680\n",
      "Epoch 76/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3757 - binary_accuracy: 0.8567\n",
      "Epoch 77/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3607 - binary_accuracy: 0.8680\n",
      "Epoch 78/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3607 - binary_accuracy: 0.8652\n",
      "Epoch 79/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3517 - binary_accuracy: 0.8652\n",
      "Epoch 80/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3520 - binary_accuracy: 0.8694\n",
      "Epoch 81/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3590 - binary_accuracy: 0.8638\n",
      "Epoch 82/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3505 - binary_accuracy: 0.8792\n",
      "Epoch 83/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3491 - binary_accuracy: 0.8764\n",
      "Epoch 84/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3547 - binary_accuracy: 0.8694\n",
      "Epoch 85/436\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.3543 - binary_accuracy: 0.8666\n",
      "Epoch 86/436\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.3575 - binary_accuracy: 0.8666\n",
      "Epoch 87/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3765 - binary_accuracy: 0.8539\n",
      "Epoch 88/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3637 - binary_accuracy: 0.8638\n",
      "Epoch 89/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3535 - binary_accuracy: 0.8652\n",
      "Epoch 90/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3521 - binary_accuracy: 0.8722\n",
      "Epoch 91/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3545 - binary_accuracy: 0.8581\n",
      "Epoch 92/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3527 - binary_accuracy: 0.8680\n",
      "Epoch 93/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3460 - binary_accuracy: 0.8722\n",
      "Epoch 94/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3495 - binary_accuracy: 0.8708\n",
      "Epoch 95/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3550 - binary_accuracy: 0.8764\n",
      "Epoch 96/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3512 - binary_accuracy: 0.8750\n",
      "Epoch 97/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3450 - binary_accuracy: 0.8722\n",
      "Epoch 98/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3621 - binary_accuracy: 0.8736\n",
      "Epoch 99/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3665 - binary_accuracy: 0.8708\n",
      "Epoch 100/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3498 - binary_accuracy: 0.8750\n",
      "Epoch 101/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3509 - binary_accuracy: 0.8750\n",
      "Epoch 102/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3688 - binary_accuracy: 0.8652\n",
      "Epoch 103/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3437 - binary_accuracy: 0.8694\n",
      "Epoch 104/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3408 - binary_accuracy: 0.8694\n",
      "Epoch 105/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3383 - binary_accuracy: 0.8792\n",
      "Epoch 106/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3354 - binary_accuracy: 0.8764\n",
      "Epoch 107/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3416 - binary_accuracy: 0.8736\n",
      "Epoch 108/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3397 - binary_accuracy: 0.8736\n",
      "Epoch 109/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3332 - binary_accuracy: 0.8708\n",
      "Epoch 110/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3373 - binary_accuracy: 0.8694\n",
      "Epoch 111/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3409 - binary_accuracy: 0.8736\n",
      "Epoch 112/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3377 - binary_accuracy: 0.8736\n",
      "Epoch 113/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3443 - binary_accuracy: 0.8694\n",
      "Epoch 114/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3396 - binary_accuracy: 0.8848\n",
      "Epoch 115/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3358 - binary_accuracy: 0.8764\n",
      "Epoch 116/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3480 - binary_accuracy: 0.8722\n",
      "Epoch 117/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3399 - binary_accuracy: 0.8778\n",
      "Epoch 118/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3320 - binary_accuracy: 0.8820\n",
      "Epoch 119/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3329 - binary_accuracy: 0.8834\n",
      "Epoch 120/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3340 - binary_accuracy: 0.8904\n",
      "Epoch 121/436\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3376 - binary_accuracy: 0.8708\n",
      "Epoch 122/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3339 - binary_accuracy: 0.8834\n",
      "Epoch 123/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3300 - binary_accuracy: 0.8764\n",
      "Epoch 124/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3350 - binary_accuracy: 0.8708\n",
      "Epoch 125/436\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.3304 - binary_accuracy: 0.8778\n",
      "Epoch 126/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3298 - binary_accuracy: 0.8834\n",
      "Epoch 127/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3365 - binary_accuracy: 0.8708\n",
      "Epoch 128/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3309 - binary_accuracy: 0.8848\n",
      "Epoch 129/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3480 - binary_accuracy: 0.8792\n",
      "Epoch 130/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3308 - binary_accuracy: 0.8764\n",
      "Epoch 131/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3334 - binary_accuracy: 0.8820\n",
      "Epoch 132/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3240 - binary_accuracy: 0.8750\n",
      "Epoch 133/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3332 - binary_accuracy: 0.8722\n",
      "Epoch 134/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3323 - binary_accuracy: 0.8750\n",
      "Epoch 135/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3463 - binary_accuracy: 0.8750\n",
      "Epoch 136/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3280 - binary_accuracy: 0.8834\n",
      "Epoch 137/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3339 - binary_accuracy: 0.8638\n",
      "Epoch 138/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3403 - binary_accuracy: 0.8778\n",
      "Epoch 139/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3365 - binary_accuracy: 0.8806\n",
      "Epoch 140/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3261 - binary_accuracy: 0.8806\n",
      "Epoch 141/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3332 - binary_accuracy: 0.8834\n",
      "Epoch 142/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3337 - binary_accuracy: 0.8722\n",
      "Epoch 143/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3590 - binary_accuracy: 0.8539\n",
      "Epoch 144/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3307 - binary_accuracy: 0.8890\n",
      "Epoch 145/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3291 - binary_accuracy: 0.8722\n",
      "Epoch 146/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3256 - binary_accuracy: 0.8806\n",
      "Epoch 147/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3305 - binary_accuracy: 0.8792\n",
      "Epoch 148/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3379 - binary_accuracy: 0.8736\n",
      "Epoch 149/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3260 - binary_accuracy: 0.8722\n",
      "Epoch 150/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3295 - binary_accuracy: 0.8806\n",
      "Epoch 151/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3254 - binary_accuracy: 0.8792\n",
      "Epoch 152/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3195 - binary_accuracy: 0.8792\n",
      "Epoch 153/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3164 - binary_accuracy: 0.8834\n",
      "Epoch 154/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3289 - binary_accuracy: 0.8792\n",
      "Epoch 155/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3220 - binary_accuracy: 0.8750\n",
      "Epoch 156/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3340 - binary_accuracy: 0.8806\n",
      "Epoch 157/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3226 - binary_accuracy: 0.8848\n",
      "Epoch 158/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3297 - binary_accuracy: 0.8764\n",
      "Epoch 159/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3252 - binary_accuracy: 0.8834\n",
      "Epoch 160/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3413 - binary_accuracy: 0.8694\n",
      "Epoch 161/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3348 - binary_accuracy: 0.8722\n",
      "Epoch 162/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3238 - binary_accuracy: 0.8848\n",
      "Epoch 163/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3170 - binary_accuracy: 0.8862\n",
      "Epoch 164/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3173 - binary_accuracy: 0.8904\n",
      "Epoch 165/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3176 - binary_accuracy: 0.8834\n",
      "Epoch 166/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3253 - binary_accuracy: 0.8820\n",
      "Epoch 167/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3237 - binary_accuracy: 0.8848\n",
      "Epoch 168/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3244 - binary_accuracy: 0.8862\n",
      "Epoch 169/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3216 - binary_accuracy: 0.8778\n",
      "Epoch 170/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3145 - binary_accuracy: 0.8778\n",
      "Epoch 171/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3190 - binary_accuracy: 0.8834\n",
      "Epoch 172/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3158 - binary_accuracy: 0.8820\n",
      "Epoch 173/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3146 - binary_accuracy: 0.8848\n",
      "Epoch 174/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3132 - binary_accuracy: 0.8806\n",
      "Epoch 175/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3141 - binary_accuracy: 0.8890\n",
      "Epoch 176/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3199 - binary_accuracy: 0.8848\n",
      "Epoch 177/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3325 - binary_accuracy: 0.8806\n",
      "Epoch 178/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3331 - binary_accuracy: 0.8694\n",
      "Epoch 179/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3244 - binary_accuracy: 0.8820\n",
      "Epoch 180/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3153 - binary_accuracy: 0.8750\n",
      "Epoch 181/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3130 - binary_accuracy: 0.8876\n",
      "Epoch 182/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3402 - binary_accuracy: 0.8581\n",
      "Epoch 183/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3361 - binary_accuracy: 0.8722\n",
      "Epoch 184/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3133 - binary_accuracy: 0.8862\n",
      "Epoch 185/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3152 - binary_accuracy: 0.8862\n",
      "Epoch 186/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3058 - binary_accuracy: 0.8975\n",
      "Epoch 187/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3143 - binary_accuracy: 0.8834\n",
      "Epoch 188/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3192 - binary_accuracy: 0.8806\n",
      "Epoch 189/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3156 - binary_accuracy: 0.8862\n",
      "Epoch 190/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3275 - binary_accuracy: 0.8792\n",
      "Epoch 191/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.3244 - binary_accuracy: 0.8862\n",
      "Epoch 192/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3226 - binary_accuracy: 0.8778\n",
      "Epoch 193/436\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3238 - binary_accuracy: 0.8876\n",
      "Epoch 194/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3341 - binary_accuracy: 0.8792\n",
      "Epoch 195/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3303 - binary_accuracy: 0.8834\n",
      "Epoch 196/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3318 - binary_accuracy: 0.8792\n",
      "Epoch 197/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3114 - binary_accuracy: 0.8806\n",
      "Epoch 198/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3174 - binary_accuracy: 0.8736\n",
      "Epoch 199/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3179 - binary_accuracy: 0.8806\n",
      "Epoch 200/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3145 - binary_accuracy: 0.8961\n",
      "Epoch 201/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3413 - binary_accuracy: 0.8820\n",
      "Epoch 202/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3290 - binary_accuracy: 0.8708\n",
      "Epoch 203/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3138 - binary_accuracy: 0.8834\n",
      "Epoch 204/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3070 - binary_accuracy: 0.8848\n",
      "Epoch 205/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3126 - binary_accuracy: 0.8876\n",
      "Epoch 206/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3128 - binary_accuracy: 0.8834\n",
      "Epoch 207/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3138 - binary_accuracy: 0.8862\n",
      "Epoch 208/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3218 - binary_accuracy: 0.8792\n",
      "Epoch 209/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3091 - binary_accuracy: 0.8862\n",
      "Epoch 210/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3074 - binary_accuracy: 0.8947\n",
      "Epoch 211/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3099 - binary_accuracy: 0.8806\n",
      "Epoch 212/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3067 - binary_accuracy: 0.8876\n",
      "Epoch 213/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3062 - binary_accuracy: 0.8862\n",
      "Epoch 214/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3001 - binary_accuracy: 0.8933\n",
      "Epoch 215/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3022 - binary_accuracy: 0.8933\n",
      "Epoch 216/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2987 - binary_accuracy: 0.8876\n",
      "Epoch 217/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3016 - binary_accuracy: 0.8834\n",
      "Epoch 218/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3052 - binary_accuracy: 0.8834\n",
      "Epoch 219/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3167 - binary_accuracy: 0.8764\n",
      "Epoch 220/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3039 - binary_accuracy: 0.8862\n",
      "Epoch 221/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3080 - binary_accuracy: 0.8820\n",
      "Epoch 222/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3078 - binary_accuracy: 0.8736\n",
      "Epoch 223/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3052 - binary_accuracy: 0.8764\n",
      "Epoch 224/436\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.3150 - binary_accuracy: 0.8806\n",
      "Epoch 225/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3047 - binary_accuracy: 0.8848\n",
      "Epoch 226/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2955 - binary_accuracy: 0.8919\n",
      "Epoch 227/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3027 - binary_accuracy: 0.8890\n",
      "Epoch 228/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3027 - binary_accuracy: 0.8919\n",
      "Epoch 229/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3083 - binary_accuracy: 0.8876\n",
      "Epoch 230/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3021 - binary_accuracy: 0.8919\n",
      "Epoch 231/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3105 - binary_accuracy: 0.8904\n",
      "Epoch 232/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3073 - binary_accuracy: 0.8947\n",
      "Epoch 233/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3043 - binary_accuracy: 0.8820\n",
      "Epoch 234/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3076 - binary_accuracy: 0.8806\n",
      "Epoch 235/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3059 - binary_accuracy: 0.8876\n",
      "Epoch 236/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3020 - binary_accuracy: 0.8890\n",
      "Epoch 237/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2983 - binary_accuracy: 0.8848\n",
      "Epoch 238/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3184 - binary_accuracy: 0.8933\n",
      "Epoch 239/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2984 - binary_accuracy: 0.8890\n",
      "Epoch 240/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3027 - binary_accuracy: 0.8876\n",
      "Epoch 241/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3025 - binary_accuracy: 0.8890\n",
      "Epoch 242/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3050 - binary_accuracy: 0.8876\n",
      "Epoch 243/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3036 - binary_accuracy: 0.8806\n",
      "Epoch 244/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3315 - binary_accuracy: 0.8708\n",
      "Epoch 245/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3127 - binary_accuracy: 0.8834\n",
      "Epoch 246/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3061 - binary_accuracy: 0.8778\n",
      "Epoch 247/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3145 - binary_accuracy: 0.8806\n",
      "Epoch 248/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3134 - binary_accuracy: 0.8919\n",
      "Epoch 249/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3038 - binary_accuracy: 0.8820\n",
      "Epoch 250/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3056 - binary_accuracy: 0.8820\n",
      "Epoch 251/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3013 - binary_accuracy: 0.8904\n",
      "Epoch 252/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3059 - binary_accuracy: 0.8904\n",
      "Epoch 253/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2990 - binary_accuracy: 0.8961\n",
      "Epoch 254/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2907 - binary_accuracy: 0.8961\n",
      "Epoch 255/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3032 - binary_accuracy: 0.8806\n",
      "Epoch 256/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3018 - binary_accuracy: 0.8862\n",
      "Epoch 257/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3005 - binary_accuracy: 0.8848\n",
      "Epoch 258/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3057 - binary_accuracy: 0.8919\n",
      "Epoch 259/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2995 - binary_accuracy: 0.8989\n",
      "Epoch 260/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3000 - binary_accuracy: 0.8820\n",
      "Epoch 261/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3113 - binary_accuracy: 0.8750\n",
      "Epoch 262/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3000 - binary_accuracy: 0.8862\n",
      "Epoch 263/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3053 - binary_accuracy: 0.8722\n",
      "Epoch 264/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2975 - binary_accuracy: 0.8933\n",
      "Epoch 265/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3092 - binary_accuracy: 0.8904\n",
      "Epoch 266/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2950 - binary_accuracy: 0.8947\n",
      "Epoch 267/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2962 - binary_accuracy: 0.8947\n",
      "Epoch 268/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2981 - binary_accuracy: 0.8904\n",
      "Epoch 269/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3088 - binary_accuracy: 0.8890\n",
      "Epoch 270/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3075 - binary_accuracy: 0.8904\n",
      "Epoch 271/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3080 - binary_accuracy: 0.8778\n",
      "Epoch 272/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3138 - binary_accuracy: 0.8890\n",
      "Epoch 273/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2986 - binary_accuracy: 0.8834\n",
      "Epoch 274/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2964 - binary_accuracy: 0.8876\n",
      "Epoch 275/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3046 - binary_accuracy: 0.8778\n",
      "Epoch 276/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3232 - binary_accuracy: 0.8778\n",
      "Epoch 277/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2990 - binary_accuracy: 0.8820\n",
      "Epoch 278/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2978 - binary_accuracy: 0.8904\n",
      "Epoch 279/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3077 - binary_accuracy: 0.8764\n",
      "Epoch 280/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2953 - binary_accuracy: 0.8890\n",
      "Epoch 281/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2961 - binary_accuracy: 0.8890\n",
      "Epoch 282/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2927 - binary_accuracy: 0.8820\n",
      "Epoch 283/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2910 - binary_accuracy: 0.8890\n",
      "Epoch 284/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3007 - binary_accuracy: 0.8848\n",
      "Epoch 285/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2947 - binary_accuracy: 0.8919\n",
      "Epoch 286/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2984 - binary_accuracy: 0.8876\n",
      "Epoch 287/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2959 - binary_accuracy: 0.8904\n",
      "Epoch 288/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2901 - binary_accuracy: 0.8876\n",
      "Epoch 289/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2950 - binary_accuracy: 0.8989\n",
      "Epoch 290/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2879 - binary_accuracy: 0.8947\n",
      "Epoch 291/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2918 - binary_accuracy: 0.8947\n",
      "Epoch 292/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3042 - binary_accuracy: 0.8876\n",
      "Epoch 293/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3032 - binary_accuracy: 0.8919\n",
      "Epoch 294/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2914 - binary_accuracy: 0.8862\n",
      "Epoch 295/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3012 - binary_accuracy: 0.8778\n",
      "Epoch 296/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3009 - binary_accuracy: 0.8876\n",
      "Epoch 297/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2831 - binary_accuracy: 0.8933\n",
      "Epoch 298/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3109 - binary_accuracy: 0.8834\n",
      "Epoch 299/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2995 - binary_accuracy: 0.8834\n",
      "Epoch 300/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2859 - binary_accuracy: 0.8933\n",
      "Epoch 301/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2899 - binary_accuracy: 0.8890\n",
      "Epoch 302/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2884 - binary_accuracy: 0.8848\n",
      "Epoch 303/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2962 - binary_accuracy: 0.8806\n",
      "Epoch 304/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3021 - binary_accuracy: 0.8947\n",
      "Epoch 305/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2974 - binary_accuracy: 0.8890\n",
      "Epoch 306/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2919 - binary_accuracy: 0.8919\n",
      "Epoch 307/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2939 - binary_accuracy: 0.8947\n",
      "Epoch 308/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2935 - binary_accuracy: 0.8862\n",
      "Epoch 309/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2939 - binary_accuracy: 0.8975\n",
      "Epoch 310/436\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.3109 - binary_accuracy: 0.8876\n",
      "Epoch 311/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2929 - binary_accuracy: 0.9003\n",
      "Epoch 312/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2969 - binary_accuracy: 0.8876\n",
      "Epoch 313/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2933 - binary_accuracy: 0.8876\n",
      "Epoch 314/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2828 - binary_accuracy: 0.8919\n",
      "Epoch 315/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2873 - binary_accuracy: 0.8876\n",
      "Epoch 316/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2825 - binary_accuracy: 0.8947\n",
      "Epoch 317/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2844 - binary_accuracy: 0.8890\n",
      "Epoch 318/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2894 - binary_accuracy: 0.8820\n",
      "Epoch 319/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2889 - binary_accuracy: 0.8890\n",
      "Epoch 320/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2824 - binary_accuracy: 0.8876\n",
      "Epoch 321/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3068 - binary_accuracy: 0.8834\n",
      "Epoch 322/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2933 - binary_accuracy: 0.8820\n",
      "Epoch 323/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2989 - binary_accuracy: 0.8890\n",
      "Epoch 324/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3034 - binary_accuracy: 0.8806\n",
      "Epoch 325/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2867 - binary_accuracy: 0.9003\n",
      "Epoch 326/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2827 - binary_accuracy: 0.8933\n",
      "Epoch 327/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2834 - binary_accuracy: 0.8975\n",
      "Epoch 328/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2840 - binary_accuracy: 0.8933\n",
      "Epoch 329/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2917 - binary_accuracy: 0.8806\n",
      "Epoch 330/436\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.2958 - binary_accuracy: 0.8876\n",
      "Epoch 331/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2902 - binary_accuracy: 0.8947\n",
      "Epoch 332/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2940 - binary_accuracy: 0.8947\n",
      "Epoch 333/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2916 - binary_accuracy: 0.8890\n",
      "Epoch 334/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2832 - binary_accuracy: 0.8862\n",
      "Epoch 335/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2905 - binary_accuracy: 0.8890\n",
      "Epoch 336/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2890 - binary_accuracy: 0.8975\n",
      "Epoch 337/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2835 - binary_accuracy: 0.8975\n",
      "Epoch 338/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2819 - binary_accuracy: 0.8947\n",
      "Epoch 339/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2831 - binary_accuracy: 0.8961\n",
      "Epoch 340/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2743 - binary_accuracy: 0.8989\n",
      "Epoch 341/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2884 - binary_accuracy: 0.8947\n",
      "Epoch 342/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2863 - binary_accuracy: 0.9003\n",
      "Epoch 343/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3017 - binary_accuracy: 0.8764\n",
      "Epoch 344/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2885 - binary_accuracy: 0.8961\n",
      "Epoch 345/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2971 - binary_accuracy: 0.8933\n",
      "Epoch 346/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2813 - binary_accuracy: 0.8904\n",
      "Epoch 347/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2844 - binary_accuracy: 0.8904\n",
      "Epoch 348/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3002 - binary_accuracy: 0.8890\n",
      "Epoch 349/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3003 - binary_accuracy: 0.8862\n",
      "Epoch 350/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2989 - binary_accuracy: 0.8904\n",
      "Epoch 351/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2863 - binary_accuracy: 0.9003\n",
      "Epoch 352/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2833 - binary_accuracy: 0.8975\n",
      "Epoch 353/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2836 - binary_accuracy: 0.8947\n",
      "Epoch 354/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3102 - binary_accuracy: 0.8778\n",
      "Epoch 355/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2959 - binary_accuracy: 0.8919\n",
      "Epoch 356/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2895 - binary_accuracy: 0.8961\n",
      "Epoch 357/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2874 - binary_accuracy: 0.8961\n",
      "Epoch 358/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2834 - binary_accuracy: 0.8820\n",
      "Epoch 359/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2802 - binary_accuracy: 0.9003\n",
      "Epoch 360/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2772 - binary_accuracy: 0.8961\n",
      "Epoch 361/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2914 - binary_accuracy: 0.8848\n",
      "Epoch 362/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2982 - binary_accuracy: 0.8919\n",
      "Epoch 363/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2897 - binary_accuracy: 0.8933\n",
      "Epoch 364/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2908 - binary_accuracy: 0.8947\n",
      "Epoch 365/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2759 - binary_accuracy: 0.8975\n",
      "Epoch 366/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2865 - binary_accuracy: 0.8947\n",
      "Epoch 367/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2848 - binary_accuracy: 0.8975\n",
      "Epoch 368/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2833 - binary_accuracy: 0.9003\n",
      "Epoch 369/436\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.2833 - binary_accuracy: 0.8862\n",
      "Epoch 370/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2913 - binary_accuracy: 0.8947\n",
      "Epoch 371/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2869 - binary_accuracy: 0.8848\n",
      "Epoch 372/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2732 - binary_accuracy: 0.8975\n",
      "Epoch 373/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2795 - binary_accuracy: 0.8890\n",
      "Epoch 374/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2772 - binary_accuracy: 0.8975\n",
      "Epoch 375/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2931 - binary_accuracy: 0.8876\n",
      "Epoch 376/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2943 - binary_accuracy: 0.8961\n",
      "Epoch 377/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2866 - binary_accuracy: 0.8904\n",
      "Epoch 378/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2827 - binary_accuracy: 0.8848\n",
      "Epoch 379/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2853 - binary_accuracy: 0.9003\n",
      "Epoch 380/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2788 - binary_accuracy: 0.8947\n",
      "Epoch 381/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2812 - binary_accuracy: 0.8961\n",
      "Epoch 382/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2956 - binary_accuracy: 0.8989\n",
      "Epoch 383/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2834 - binary_accuracy: 0.9045\n",
      "Epoch 384/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2936 - binary_accuracy: 0.8919\n",
      "Epoch 385/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2838 - binary_accuracy: 0.8919\n",
      "Epoch 386/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2876 - binary_accuracy: 0.8890\n",
      "Epoch 387/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2885 - binary_accuracy: 0.8933\n",
      "Epoch 388/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2780 - binary_accuracy: 0.9003\n",
      "Epoch 389/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2927 - binary_accuracy: 0.8792\n",
      "Epoch 390/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2805 - binary_accuracy: 0.8933\n",
      "Epoch 391/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2947 - binary_accuracy: 0.8904\n",
      "Epoch 392/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2900 - binary_accuracy: 0.8876\n",
      "Epoch 393/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2986 - binary_accuracy: 0.8876\n",
      "Epoch 394/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2812 - binary_accuracy: 0.9031\n",
      "Epoch 395/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2804 - binary_accuracy: 0.8947\n",
      "Epoch 396/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2774 - binary_accuracy: 0.9017\n",
      "Epoch 397/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2749 - binary_accuracy: 0.8933\n",
      "Epoch 398/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2745 - binary_accuracy: 0.9017\n",
      "Epoch 399/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2837 - binary_accuracy: 0.8961\n",
      "Epoch 400/436\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2914 - binary_accuracy: 0.8876\n",
      "Epoch 401/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2859 - binary_accuracy: 0.8933\n",
      "Epoch 402/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2914 - binary_accuracy: 0.8848\n",
      "Epoch 403/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2865 - binary_accuracy: 0.8947\n",
      "Epoch 404/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2806 - binary_accuracy: 0.8890\n",
      "Epoch 405/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3010 - binary_accuracy: 0.8806\n",
      "Epoch 406/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2782 - binary_accuracy: 0.8961\n",
      "Epoch 407/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2832 - binary_accuracy: 0.8947\n",
      "Epoch 408/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2778 - binary_accuracy: 0.8975\n",
      "Epoch 409/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2817 - binary_accuracy: 0.9045\n",
      "Epoch 410/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2757 - binary_accuracy: 0.8989\n",
      "Epoch 411/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2834 - binary_accuracy: 0.8961\n",
      "Epoch 412/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2884 - binary_accuracy: 0.8961\n",
      "Epoch 413/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2836 - binary_accuracy: 0.8904\n",
      "Epoch 414/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2785 - binary_accuracy: 0.8961\n",
      "Epoch 415/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2835 - binary_accuracy: 0.8947\n",
      "Epoch 416/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2796 - binary_accuracy: 0.8989\n",
      "Epoch 417/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2855 - binary_accuracy: 0.8947\n",
      "Epoch 418/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2871 - binary_accuracy: 0.8919\n",
      "Epoch 419/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2861 - binary_accuracy: 0.8961\n",
      "Epoch 420/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2947 - binary_accuracy: 0.8919\n",
      "Epoch 421/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2958 - binary_accuracy: 0.8947\n",
      "Epoch 422/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2790 - binary_accuracy: 0.8989\n",
      "Epoch 423/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2746 - binary_accuracy: 0.9087\n",
      "Epoch 424/436\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.2786 - binary_accuracy: 0.9017\n",
      "Epoch 425/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2746 - binary_accuracy: 0.9017\n",
      "Epoch 426/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2786 - binary_accuracy: 0.8961\n",
      "Epoch 427/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2768 - binary_accuracy: 0.8919\n",
      "Epoch 428/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2943 - binary_accuracy: 0.8947\n",
      "Epoch 429/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2851 - binary_accuracy: 0.8919\n",
      "Epoch 430/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2829 - binary_accuracy: 0.8947\n",
      "Epoch 431/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2807 - binary_accuracy: 0.8933\n",
      "Epoch 432/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2707 - binary_accuracy: 0.8989\n",
      "Epoch 433/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2760 - binary_accuracy: 0.9045\n",
      "Epoch 434/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2695 - binary_accuracy: 0.8989\n",
      "Epoch 435/436\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.2769 - binary_accuracy: 0.8989\n",
      "Epoch 436/436\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.2685 - binary_accuracy: 0.9003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11fa34610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "  hypermodel,\n",
    "  keras.layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=tf.losses.BinaryCrossentropy(from_logits=False), optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=['val_binary_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step\n",
      "     Pclass  Sex   Age  SibSp  Parch      Fare  Embarked\n",
      "0         3    1  34.5      0      0    7.8292         2\n",
      "1         3    0  47.0      1      0    7.0000         0\n",
      "2         2    1  62.0      0      0    9.6875         2\n",
      "3         3    1  27.0      0      0    8.6625         0\n",
      "4         3    0  22.0      1      1   12.2875         0\n",
      "..      ...  ...   ...    ...    ...       ...       ...\n",
      "409       3    0   3.0      1      1   13.7750         0\n",
      "411       1    0  37.0      1      0   90.0000         2\n",
      "412       3    0  28.0      0      0    7.7750         0\n",
      "414       1    0  39.0      0      0  108.9000         1\n",
      "415       3    1  38.5      0      0    7.2500         0\n",
      "\n",
      "[331 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "results = export_model.predict(test_data)\n",
    "with open(\"ai_submission.csv\", \"w\") as f:\n",
    "    f.write(\"PassengerId,Survived\\n\")\n",
    "    for i, val in enumerate(results):\n",
    "        f.write(f\"{test_ids[i]},{round(val[0])}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7449bf2e1a3d0638a4bbe0f1a78cec1031b8eced4e6e658e7dcc8416da63db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
