{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load models\n",
    "Model can resume training where it left off to avoid long training times. You can also share your model with others. Typically these things are shared:\n",
    "- code to create the model\n",
    "- the model's trained weights/parameters\n",
    "\n",
    "#### Note\n",
    "There is more than one way of going about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the MNIST dataset, however, only using the first 1,000 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 17:53:23.500903: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\", input_shape=(784,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create a callback that saves the weights only during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/checkpoint.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've set the model to save, we're going to train a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 1.3203 - sparse_categorical_accuracy: 0.6178\n",
      "Epoch 1: saving model to training_1/checkpoint.ckpt\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.2092 - sparse_categorical_accuracy: 0.6540 - val_loss: 0.7684 - val_sparse_categorical_accuracy: 0.7490\n",
      "Epoch 2/10\n",
      "21/32 [==================>...........] - ETA: 0s - loss: 0.4611 - sparse_categorical_accuracy: 0.8735\n",
      "Epoch 2: saving model to training_1/checkpoint.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4376 - sparse_categorical_accuracy: 0.8800 - val_loss: 0.5342 - val_sparse_categorical_accuracy: 0.8320\n",
      "Epoch 3/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.2907 - sparse_categorical_accuracy: 0.9271\n",
      "Epoch 3: saving model to training_1/checkpoint.ckpt\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 0.2876 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.4818 - val_sparse_categorical_accuracy: 0.8410\n",
      "Epoch 4/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.2135 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 4: saving model to training_1/checkpoint.ckpt\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.2137 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.4440 - val_sparse_categorical_accuracy: 0.8630\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1501 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 5: saving model to training_1/checkpoint.ckpt\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.1501 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.4406 - val_sparse_categorical_accuracy: 0.8620\n",
      "Epoch 6/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.1195 - sparse_categorical_accuracy: 0.9752\n",
      "Epoch 6: saving model to training_1/checkpoint.ckpt\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 0.1170 - sparse_categorical_accuracy: 0.9760 - val_loss: 0.4358 - val_sparse_categorical_accuracy: 0.8580\n",
      "Epoch 7/10\n",
      "20/32 [=================>............] - ETA: 0s - loss: 0.0932 - sparse_categorical_accuracy: 0.9812\n",
      "Epoch 7: saving model to training_1/checkpoint.ckpt\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0937 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.4420 - val_sparse_categorical_accuracy: 0.8560\n",
      "Epoch 8/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.0682 - sparse_categorical_accuracy: 0.9935\n",
      "Epoch 8: saving model to training_1/checkpoint.ckpt\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.0680 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.4191 - val_sparse_categorical_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.0477 - sparse_categorical_accuracy: 0.9986\n",
      "Epoch 9: saving model to training_1/checkpoint.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0496 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.4201 - val_sparse_categorical_accuracy: 0.8590\n",
      "Epoch 10/10\n",
      "26/32 [=======================>......] - ETA: 0s - loss: 0.0362 - sparse_categorical_accuracy: 1.0000\n",
      "Epoch 10: saving model to training_1/checkpoint.ckpt\n",
      "32/32 [==============================] - 1s 20ms/step - loss: 0.0386 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4036 - val_sparse_categorical_accuracy: 0.8730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f0b0a60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels), callbacks=[ckpt_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint', 'checkpoint.ckpt.index', 'checkpoint.ckpt.data-00000-of-00001']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as two models share the same architecture you can share weights between them. So, when restoring a model from weights-only, create a model with the same architecture as the original model and then set its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly odd, but we're intentionally creating an untrained model and evaluating its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.2714 - sparse_categorical_accuracy: 0.1750 - 137ms/epoch - 4ms/step\n",
      "Untrained model accuracy 17.499999701976776%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Untrained model accuracy {100 * acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the weights from our previous training session and testing again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4036 - sparse_categorical_accuracy: 0.8730 - 60ms/epoch - 2ms/step\n",
      "Untrained model accuracy 87.30000257492065%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Untrained model accuracy {100 * acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various ways to get unique names, and you can manupilate the saving frequency.\n",
    "\n",
    "Train a new model, and save uniquely named checkpoints once every five epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: saving model to training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 10: saving model to training_2/cp-0010.ckpt\n",
      "\n",
      "Epoch 15: saving model to training_2/cp-0015.ckpt\n",
      "\n",
      "Epoch 20: saving model to training_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 25: saving model to training_2/cp-0025.ckpt\n",
      "\n",
      "Epoch 30: saving model to training_2/cp-0030.ckpt\n",
      "\n",
      "Epoch 35: saving model to training_2/cp-0035.ckpt\n",
      "\n",
      "Epoch 40: saving model to training_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 45: saving model to training_2/cp-0045.ckpt\n",
      "\n",
      "Epoch 50: saving model to training_2/cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f267e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, verbose=1, save_weights_only=True, save_freq=5*batch_size\n",
    ")\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=50, batch_size=batch_size, callbacks=[ckpt_callback] ,validation_data=(test_images, test_labels), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp-0005.ckpt.data-00000-of-00001',\n",
       " 'cp-0050.ckpt.index',\n",
       " 'cp-0005.ckpt.index',\n",
       " 'cp-0050.ckpt.data-00000-of-00001',\n",
       " 'checkpoint',\n",
       " 'cp-0020.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.index',\n",
       " 'cp-0030.ckpt.index',\n",
       " 'cp-0025.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.data-00000-of-00001',\n",
       " 'cp-0035.ckpt.index',\n",
       " 'cp-0010.ckpt.index',\n",
       " 'cp-0045.ckpt.index',\n",
       " 'cp-0045.ckpt.data-00000-of-00001',\n",
       " 'cp-0010.ckpt.data-00000-of-00001',\n",
       " 'cp-0035.ckpt.data-00000-of-00001',\n",
       " 'cp-0015.ckpt.index',\n",
       " 'cp-0040.ckpt.index',\n",
       " 'cp-0025.ckpt.index',\n",
       " 'cp-0030.ckpt.data-00000-of-00001',\n",
       " 'cp-0040.ckpt.data-00000-of-00001',\n",
       " 'cp-0015.ckpt.data-00000-of-00001',\n",
       " 'cp-0020.ckpt.index']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_2/cp-0050.ckpt\n"
     ]
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing this by resetting the model and loading the latest checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4751 - sparse_categorical_accuracy: 0.8730 - 166ms/epoch - 5ms/step\n",
      "Restored model accuracy 87.30%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights(latest)\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n",
    "print(f\"Restored model accuracy {acc * 100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are these files?\n",
    "The above code stores the weights to a collection of checkpoint-formatted files that contain only the trained weights in a binary format. Checkpoints contain:\n",
    "- one or more \"shards\" that contain the model's weights\n",
    "- an index file that indicates which weights are stored in which shard\n",
    "\n",
    "If you are training a model on a single machine, you'll have one shard with the suffix: `.data-00000-of-00001`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving weights manually\n",
    "By default the TensorFlow checkpoint format (`.ckpt` extension) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4751 - sparse_categorical_accuracy: 0.8730 - 148ms/epoch - 5ms/step\n",
      "Restored model accuracy 87.30%\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Reset and test\n",
    "model = create_model()\n",
    "\n",
    "model.load_weights(\"./checkpoints/my_checkpoint\")\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Restored model accuracy {acc*100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the entire model\n",
    "Call `model.save` to save a model's architecture, weights, and training configuration in a single file/folder. Can either be in TensorFlow's `SavedModel` format or `HDF5`, `SavedModel` is default in TF2.x.\n",
    "\n",
    "You can use both these formats to load into TensorFlow.js (still unclear why you'd train here... but you can) or TensorFlow Lite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SavedModel format\n",
    "This is the default format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 1s 8ms/step - loss: 1.1341 - sparse_categorical_accuracy: 0.6750\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4364 - sparse_categorical_accuracy: 0.8710\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2961 - sparse_categorical_accuracy: 0.9220\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2156 - sparse_categorical_accuracy: 0.9520\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1703 - sparse_categorical_accuracy: 0.9590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 18:36:40.347073: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mmy_model\u001b[m\u001b[m\n",
      "\u001b[34massets\u001b[m\u001b[m            keras_metadata.pb saved_model.pb    \u001b[34mvariables\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls saved_model\n",
    "!ls saved_model/my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python code from earlier is not needed and the model can be loaded from nothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4490 - sparse_categorical_accuracy: 0.8600 - 73ms/epoch - 2ms/step\n",
      "Restored model accuracy: 86.00\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Restored model accuracy: {acc*100:5.2f}\")\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 1s 5ms/step - loss: 1.1458 - sparse_categorical_accuracy: 0.6680\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4123 - sparse_categorical_accuracy: 0.8940\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2778 - sparse_categorical_accuracy: 0.9270\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2059 - sparse_categorical_accuracy: 0.9480\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1664 - sparse_categorical_accuracy: 0.9640\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4462 - sparse_categorical_accuracy: 0.8580 - 340ms/epoch - 11ms/step\n",
      "Restored model accuracy: 85.80\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Restored model accuracy: {acc*100:5.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras saves pretty much everything, however, is not able to save the `v1.x` optimizers (from `tf.compat.v1.train`) since they aren't compatible with checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some extra steps to save custom objects in HDF5. [link](https://www.tensorflow.org/tutorials/keras/save_and_load#saving_custom_objects)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9160c6cf5aab06277c81118e8682660151e6ad391d4cc63a71724804c8a65c36"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
