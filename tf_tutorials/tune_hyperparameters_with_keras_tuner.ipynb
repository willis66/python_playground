{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras tuner is a seperate library that helps choose optimal hyperparameters of a TF program: this is called *hyperparameter tuning* or *hypertuning*. there are two different types of hyperparameters\n",
    "1. **model hyperparameters** which influence model selection such as the number and width of hidden layers\n",
    "2. **Algorithm hyperparameters** which influence the speed and quality of the learning algorithm such as the learning rate for Stochastic Gradient Descent (SGD) and the number of nearest neighbors for a k Nearest Neighbors (KNN) classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when you set up a model for hypertuning you have to define the search space which can be done by: \n",
    "- using a model builder function\n",
    "- or by subclassing the `HyperModel` class of the Keras Tuner API\n",
    "there are two pre-defined hypermodel classes that can be used in computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    # Choose an optimal value between 32-512\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the tuner must be instantiated to perform tuning. the keras tuner has four different types. `RandomSearch`, `HyperBand`, `BayesianOptimization`, and `Sklearn`. this will be using the `HyperBand`. \n",
    "\n",
    "the hypermodel must be specified. the `objective` (what should be optimized) and the max number of epochs to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 21:53:49.088128: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. Hyperband determines the number of models to train in a bracket by computing 1 + logfactor(max_epochs) and rounding it up to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same args as `tf.keras.model.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 02m 22s]\n",
      "val_accuracy: 0.8814166784286499\n",
      "\n",
      "Best val_accuracy So Far: 0.8868333101272583\n",
      "Total elapsed time: 00h 16m 54s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 96 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alright so all that was just finding the best hyperparameters to use for training. now we're solving for the best number of epochs to train with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5216 - accuracy: 0.8166 - val_loss: 0.4591 - val_accuracy: 0.8315\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3921 - accuracy: 0.8588 - val_loss: 0.4077 - val_accuracy: 0.8512\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3513 - accuracy: 0.8722 - val_loss: 0.3587 - val_accuracy: 0.8725\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3241 - accuracy: 0.8813 - val_loss: 0.3402 - val_accuracy: 0.8788\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3073 - accuracy: 0.8864 - val_loss: 0.3304 - val_accuracy: 0.8800\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2915 - accuracy: 0.8917 - val_loss: 0.3229 - val_accuracy: 0.8817\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2781 - accuracy: 0.8963 - val_loss: 0.3232 - val_accuracy: 0.8843\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2681 - accuracy: 0.9004 - val_loss: 0.3312 - val_accuracy: 0.8824\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2585 - accuracy: 0.9030 - val_loss: 0.3702 - val_accuracy: 0.8737\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2497 - accuracy: 0.9069 - val_loss: 0.3208 - val_accuracy: 0.8829\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2404 - accuracy: 0.9101 - val_loss: 0.3160 - val_accuracy: 0.8847\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2316 - accuracy: 0.9128 - val_loss: 0.3306 - val_accuracy: 0.8838\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2251 - accuracy: 0.9158 - val_loss: 0.3169 - val_accuracy: 0.8893\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2196 - accuracy: 0.9180 - val_loss: 0.3101 - val_accuracy: 0.8926\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2147 - accuracy: 0.9205 - val_loss: 0.3247 - val_accuracy: 0.8863\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2057 - accuracy: 0.9231 - val_loss: 0.3249 - val_accuracy: 0.8892\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2029 - accuracy: 0.9254 - val_loss: 0.3302 - val_accuracy: 0.8909\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1978 - accuracy: 0.9258 - val_loss: 0.3340 - val_accuracy: 0.8891\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1932 - accuracy: 0.9286 - val_loss: 0.3306 - val_accuracy: 0.8907\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1882 - accuracy: 0.9300 - val_loss: 0.3416 - val_accuracy: 0.8907\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1829 - accuracy: 0.9312 - val_loss: 0.3493 - val_accuracy: 0.8877\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1777 - accuracy: 0.9335 - val_loss: 0.3574 - val_accuracy: 0.8883\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1733 - accuracy: 0.9348 - val_loss: 0.3457 - val_accuracy: 0.8917\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1692 - accuracy: 0.9369 - val_loss: 0.3710 - val_accuracy: 0.8871\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1657 - accuracy: 0.9386 - val_loss: 0.3479 - val_accuracy: 0.8906\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1633 - accuracy: 0.9388 - val_loss: 0.3770 - val_accuracy: 0.8867\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1597 - accuracy: 0.9398 - val_loss: 0.3680 - val_accuracy: 0.8907\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.1547 - accuracy: 0.9416 - val_loss: 0.3609 - val_accuracy: 0.8927\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1528 - accuracy: 0.9423 - val_loss: 0.3645 - val_accuracy: 0.8932\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1493 - accuracy: 0.9444 - val_loss: 0.3743 - val_accuracy: 0.8906\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1440 - accuracy: 0.9466 - val_loss: 0.3937 - val_accuracy: 0.8866\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1404 - accuracy: 0.9490 - val_loss: 0.3970 - val_accuracy: 0.8840\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1399 - accuracy: 0.9479 - val_loss: 0.3661 - val_accuracy: 0.8936\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1349 - accuracy: 0.9500 - val_loss: 0.4030 - val_accuracy: 0.8919\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1329 - accuracy: 0.9514 - val_loss: 0.3923 - val_accuracy: 0.8924\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1275 - accuracy: 0.9525 - val_loss: 0.4311 - val_accuracy: 0.8846\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1290 - accuracy: 0.9524 - val_loss: 0.4255 - val_accuracy: 0.8892\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1259 - accuracy: 0.9541 - val_loss: 0.4202 - val_accuracy: 0.8892\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1242 - accuracy: 0.9532 - val_loss: 0.4258 - val_accuracy: 0.8892\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1215 - accuracy: 0.9544 - val_loss: 0.4160 - val_accuracy: 0.8905\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1182 - accuracy: 0.9560 - val_loss: 0.4379 - val_accuracy: 0.8917\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1177 - accuracy: 0.9557 - val_loss: 0.4334 - val_accuracy: 0.8900\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1149 - accuracy: 0.9576 - val_loss: 0.4585 - val_accuracy: 0.8871\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1117 - accuracy: 0.9583 - val_loss: 0.4595 - val_accuracy: 0.8844\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1093 - accuracy: 0.9591 - val_loss: 0.4541 - val_accuracy: 0.8881\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1110 - accuracy: 0.9582 - val_loss: 0.4553 - val_accuracy: 0.8868\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1052 - accuracy: 0.9604 - val_loss: 0.4524 - val_accuracy: 0.8898\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1035 - accuracy: 0.9612 - val_loss: 0.4951 - val_accuracy: 0.8849\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1039 - accuracy: 0.9620 - val_loss: 0.4548 - val_accuracy: 0.8937\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1004 - accuracy: 0.9627 - val_loss: 0.4720 - val_accuracy: 0.8862\n",
      "Best epoch: 49\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we're going to re-instantiate the model using that number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5245 - accuracy: 0.8175 - val_loss: 0.4218 - val_accuracy: 0.8497\n",
      "Epoch 2/49\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3906 - accuracy: 0.8602 - val_loss: 0.3828 - val_accuracy: 0.8617\n",
      "Epoch 3/49\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3513 - accuracy: 0.8722 - val_loss: 0.3548 - val_accuracy: 0.8710\n",
      "Epoch 4/49\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3243 - accuracy: 0.8821 - val_loss: 0.3373 - val_accuracy: 0.8817\n",
      "Epoch 5/49\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3047 - accuracy: 0.8879 - val_loss: 0.3401 - val_accuracy: 0.8793\n",
      "Epoch 6/49\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2938 - accuracy: 0.8922 - val_loss: 0.3515 - val_accuracy: 0.8728\n",
      "Epoch 7/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2787 - accuracy: 0.8985 - val_loss: 0.3309 - val_accuracy: 0.8812\n",
      "Epoch 8/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2696 - accuracy: 0.8999 - val_loss: 0.3342 - val_accuracy: 0.8802\n",
      "Epoch 9/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2595 - accuracy: 0.9035 - val_loss: 0.3201 - val_accuracy: 0.8856\n",
      "Epoch 10/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2492 - accuracy: 0.9077 - val_loss: 0.3225 - val_accuracy: 0.8867\n",
      "Epoch 11/49\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2405 - accuracy: 0.9105 - val_loss: 0.3398 - val_accuracy: 0.8842\n",
      "Epoch 12/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2310 - accuracy: 0.9139 - val_loss: 0.3301 - val_accuracy: 0.8880\n",
      "Epoch 13/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2253 - accuracy: 0.9161 - val_loss: 0.3305 - val_accuracy: 0.8874\n",
      "Epoch 14/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2189 - accuracy: 0.9181 - val_loss: 0.3357 - val_accuracy: 0.8855\n",
      "Epoch 15/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2115 - accuracy: 0.9207 - val_loss: 0.3192 - val_accuracy: 0.8912\n",
      "Epoch 16/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2056 - accuracy: 0.9237 - val_loss: 0.3340 - val_accuracy: 0.8884\n",
      "Epoch 17/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2017 - accuracy: 0.9246 - val_loss: 0.3312 - val_accuracy: 0.8906\n",
      "Epoch 18/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1952 - accuracy: 0.9271 - val_loss: 0.3359 - val_accuracy: 0.8884\n",
      "Epoch 19/49\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1901 - accuracy: 0.9299 - val_loss: 0.3401 - val_accuracy: 0.8866\n",
      "Epoch 20/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1855 - accuracy: 0.9306 - val_loss: 0.3500 - val_accuracy: 0.8858\n",
      "Epoch 21/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1800 - accuracy: 0.9324 - val_loss: 0.3396 - val_accuracy: 0.8910\n",
      "Epoch 22/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1759 - accuracy: 0.9337 - val_loss: 0.3850 - val_accuracy: 0.8788\n",
      "Epoch 23/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1726 - accuracy: 0.9355 - val_loss: 0.3587 - val_accuracy: 0.8896\n",
      "Epoch 24/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1675 - accuracy: 0.9373 - val_loss: 0.3628 - val_accuracy: 0.8876\n",
      "Epoch 25/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1635 - accuracy: 0.9388 - val_loss: 0.3745 - val_accuracy: 0.8886\n",
      "Epoch 26/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1587 - accuracy: 0.9424 - val_loss: 0.3919 - val_accuracy: 0.8809\n",
      "Epoch 27/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1573 - accuracy: 0.9418 - val_loss: 0.3800 - val_accuracy: 0.8885\n",
      "Epoch 28/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1537 - accuracy: 0.9424 - val_loss: 0.3950 - val_accuracy: 0.8872\n",
      "Epoch 29/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1483 - accuracy: 0.9451 - val_loss: 0.3722 - val_accuracy: 0.8907\n",
      "Epoch 30/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1464 - accuracy: 0.9450 - val_loss: 0.3873 - val_accuracy: 0.8879\n",
      "Epoch 31/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1442 - accuracy: 0.9456 - val_loss: 0.3833 - val_accuracy: 0.8882\n",
      "Epoch 32/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1399 - accuracy: 0.9471 - val_loss: 0.4041 - val_accuracy: 0.8860\n",
      "Epoch 33/49\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1364 - accuracy: 0.9483 - val_loss: 0.4026 - val_accuracy: 0.8857\n",
      "Epoch 34/49\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1342 - accuracy: 0.9495 - val_loss: 0.3993 - val_accuracy: 0.8885\n",
      "Epoch 35/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1323 - accuracy: 0.9501 - val_loss: 0.4206 - val_accuracy: 0.8862\n",
      "Epoch 36/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1302 - accuracy: 0.9519 - val_loss: 0.4145 - val_accuracy: 0.8898\n",
      "Epoch 37/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1255 - accuracy: 0.9535 - val_loss: 0.4114 - val_accuracy: 0.8882\n",
      "Epoch 38/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1261 - accuracy: 0.9524 - val_loss: 0.4678 - val_accuracy: 0.8801\n",
      "Epoch 39/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1231 - accuracy: 0.9535 - val_loss: 0.4168 - val_accuracy: 0.8901\n",
      "Epoch 40/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1172 - accuracy: 0.9542 - val_loss: 0.4381 - val_accuracy: 0.8897\n",
      "Epoch 41/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1185 - accuracy: 0.9556 - val_loss: 0.4300 - val_accuracy: 0.8890\n",
      "Epoch 42/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1169 - accuracy: 0.9568 - val_loss: 0.4533 - val_accuracy: 0.8867\n",
      "Epoch 43/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1150 - accuracy: 0.9572 - val_loss: 0.4571 - val_accuracy: 0.8816\n",
      "Epoch 44/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1091 - accuracy: 0.9584 - val_loss: 0.4514 - val_accuracy: 0.8866\n",
      "Epoch 45/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1091 - accuracy: 0.9592 - val_loss: 0.4569 - val_accuracy: 0.8882\n",
      "Epoch 46/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1069 - accuracy: 0.9599 - val_loss: 0.4569 - val_accuracy: 0.8856\n",
      "Epoch 47/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1064 - accuracy: 0.9599 - val_loss: 0.4580 - val_accuracy: 0.8876\n",
      "Epoch 48/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1029 - accuracy: 0.9621 - val_loss: 0.4705 - val_accuracy: 0.8878\n",
      "Epoch 49/49\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1036 - accuracy: 0.9611 - val_loss: 0.4791 - val_accuracy: 0.8879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124e85ee0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can evaluate this hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5123 - accuracy: 0.8838\n",
      "[test loss, test accuracy]: [0.51230388879776, 0.8838000297546387]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `my_dir/intro_to_kt` directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. To disable this behavior, pass an additional `overwrite=True` argument while instantiating the tuner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link](https://www.tensorflow.org/tutorials/keras/keras_tuner#train_the_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9160c6cf5aab06277c81118e8682660151e6ad391d4cc63a71724804c8a65c36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
